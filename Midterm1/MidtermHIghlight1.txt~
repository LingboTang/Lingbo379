a) Describe three advantages and one disadvatage of Multiprocessor System over Single Processor Systems

	Advantages: 
		Increased throughput. By increasing the number of processors, we expect to get more work done in less time. The speed-up with N processors is not N, however; rather, it is less than N.

		Economy of scale. Multiprocessor systems can cost less than equivalent multiple single-processor systems, because they can share peripherals, mass storage, and power supplies

		Increased reliability. If functions can be distributed properly among several processors, then the failure of one processor will not halt the system, only slow it donw.

	Disadvantage:
		Data consistency. In multiprocessor environments, it is hard to maintain data consistency. Multiple copies of the same data may reside in the local storage of each CPU. Whenever one CPU alters the data,it is necessary to reflect the update operation on each copy of the data.

b) Write the difference between API and System Call. What are the benefits of using API rather than using direct system call?
	System calls are programming interfaces to the services provided by the OS whereas an API provides application programmers with an interface to a system call. API invokes the actual system call on behalf of the application programmer. API hides the complexity of the actual system call and also improves the portability of the written code.

c)Describe five different states that a process may have
	The possible states of a process are: new running waiting ready and terminated. The process is created while in the new state. In the running and waiting state, the process is executing or waiting for an event to occur, respectively. The ready state occurs when the process is ready and waiting to be assigned to a processor and should not be confused with the waiting state mentioned earlier. After the process is finished executing its code, it enters the termination state.

d) Advantages and disadvantage of shared memory and message passing communication systems.

	Message passing is useful for exchanging smaller amounts of data, because no conflicts need be avoided. Message passing is also easier to implement in a distributed system than shared memory.

	Shared memory can be faster than message passing since message-passing sytstems are typically implemented using system calls and thus require the more time-consuming task of kernel intervention. In shared-memory systems, system calls are required only to establish shared memory regions. Once shared memory is established, all accesses are treated as routine memory accesses, and no assistance from the kernel is required.

	Shared memory sufferes from cahe coherency issues, which arise because shared data migrate among the several caches.

e) Benefits of multithreaded programming:
	
	The benefits of multithread programming fall into the categories: responsiveness, resource sharing, economy, and utilization of multiprocessor architectures. Responsiveness means that a multithreaded program can allow a program to run even if part of it is blocked. Resource sharing occurs when an application has several different threads of activity within the same address space. Threads share the resources of the process to which they belong. As a result, it is more economical to create new threads than new processes. Finally, a single-threaded process can only execute on one processor regardless of the number of processors actually present. Multiple threads can run on multiple processors, thereby increasing efficiency.

f) Multithreaded C that creates two threads to sum up n numberic values. Assume that all data are already loaded into int data[], and you do not need to write code to check erroneous situations.

	See multi-test.c






Processd vs Thread
	Per process items		Per thread items
	Address space			Program counter
	Global variables		Registers
	Open files 				Stack
	Child processes			State
	Pending alarms
	Signals and signal handlers
	Accounting information


Single Multithreaded Processes vs. Multithreaded Processes

	Single						Multi
	code    data   files		code        data         files
	registers	   stack		registers   registers	 registers
								stack		stack		 stack				

			|					 |			 |			  |
	thread	|					 |			 |			  |		thread
			|					 |			 |			  |




Benefits:
		Responsiveness -may allow continued execution if part ofe process is blocked, especially important for user interfaces.
		Resource Sharing - threads share resources of the initiating process, greater output with limited resources
		Economy - cheaper than process creation, thread switching has lower overhead than context switching
		Scalability - Process can take advantage of muiltiprocessor architectures

Multicore Programming
	
		Multicore or multi processor systems impose challenges for programmers:
				Dividing activities - identify what can be parallelized
				Balance - ecah task should perform  "enough" work to be worth as a separate thread
				Data splitting - data must also be divided so that tasks can use it on their separate cores
				Data dependency - synchronization in data accesses
				Testing and debugging - more difficult to debug possible execution paths from threads on multiple cores

	
Parallel Computing

		Parallelism implies a system can perform more than one task simultaneously
		Concurrency supportsd more than one task making progress *On single core, scheduler provides concurrency
		Data parallelism - distributes subsets of the data across multiple cores, same operation on each
		Task parallelism - distributes threads across cores, each thread performs unique operation
		
User threadsd - management done by user-level threads library

	Three primary thread libraries:
			POSIX Pthreads		Windows threads		Java threads

Kernel threads - Supported by the kernel

All OSes support multithreads

Multithreading models
		Many-to-One:
			Many user-level threadsd mapped to single kernel thread
			One blocking thread causes all threads to block
			Multiple threads cannot run in parallel on multicore system because only one may be in kernel at a time
		One-to-One
			One user-level to one kernel thread
			Creating a user-level thread creat4esa kernelo thread
			More concurrency than many-to-one
			Number of threads sometimes restricted due to overhead			
		Many-to-Many
			Allows the operating system to create a sufficient number of kernel threads
		Two-level Model
			Similar to MM, except that it allows a user thread to b3e bound to a kernel thread
			Examples: IPIX HP-UX Tru64 UNIX Solaris 8 and earlier

Thread Libraries
		Thread Library provides programmer with API for creating and managing threads

Two primary ways of implementing
		Library entirely in user space
		Kernel-level library supported by the OS

Pthreads
		May be provided either as user-level or kernel-level
		A POSIX standard API for thread creation and synchronization
		Specification, not implementation
		API specifies behavior of the thread library, implementation is up to development of the library
		Common in UNIX operating systems (Solaris, Linux, Mac OS X)
		


Thread Pools
		Unlimited threads may exhaust resources
		During process startup, a number of threads are created and are kept in a pool
			Process awakes a thread from the pool and assigns some task whenever necessary
			When task is finished, the thread goes to pool again and waits for any new task
		Advantages:
			Faster to do a task with an exisiting thread than creating a new one
			Limits the numnber of threads by the pool size
			Separates task to be performed from mechanics of creating the task
		Pool size can be adjusted dynamically based on usage pattern

Thread Issues
		Behaviour of fork() and exec() system calls
		Signal handling - Synchronous and asynchronous
		Thread cancellation -Asynchronous or deferred
		Thread-local storage

fork() and exec()
		Does fork() duplicate only the calling thread or all threads?
		Two variations. New process includes
		
			only the calling thread
			All threads
		exec() usually works as normal - replace the running process including all threads
		If fork() is immediately followed by exec()
			No need to duplicate all threads


Signal Handling
		Signals are used in UNIX systems to notify a process about a particular event
		When an event occurs
			1. Signal is generated by the event
			2. Signal is delivered to a process
			3. Signal is handled by a signal handler
		Every signal has a default handler that kernel runs when it handles the signal
		User-defined signal handler can override default

		For ST process signal passing is trivial
		For MT process,where to deliver the signal?
			Synchronous signal (like SIGSEGV): sent to the thread that caused it\
			Asynchronous signals: not clear. Some asynchronous signals (like SIGINT) should be sen to all threads

Thread Cancellation
		Terminating a thread before it has finished
		Thread to be cancelled is called target thread
		Two general approaches:
			Asynchronous cancellation terminates the target thread immediately - target thread's all resources may not be released
			Deffered cancellation allows the target thread to periodically check if it should be cancelled - Target tghread has the chance to release all resources

		Actual cancellation depends on thread state

			MODE 				STATE 				TYPE
			OFF					Disabled			-
			Deferred			Enabled				Deferred
			Asynchronous		Enabled				Asynchronous
		
		If thread has cancellation disabled, cancellation remains pending until thread enables it
		Default type is deferred
			Cancellation only occurs when threadf reaches cancellation point
			Executes some cleanup code


Thread-Local Storage
		Thread-Local storage allows each thread to have its own copy of data
		Different from local variables
			Local variables visible only during single function call
			TLS visible across function invocations
		Similar to static data

Linux Threads
		Both processes and threads are termed as tasks
		Thread creation is done through clone() system call
		clone() allows a child task to share the resources of the parent task
			FLags are set during clone() system call
			
			Flag				Meaning
			CLONE_PS			File-system information is shared
			CLONE_VM			The same memory spce is shared
			CLONE_SIGHAND		Signal handlers are shared
			CLONE_FILES			The set of open files is shared

		struct task_struct represents tasks

